## PowerTransformer in Machine Learning

-> This project demonstrates the use of **scikit-learn’s PowerTransformer** to stabilize variance, reduce skewness, and make features more normally distributed.  
-> It’s a powerful preprocessing technique for improving model performance, especially when dealing with non-Gaussian data.


# Topics Covered:-
-> Introduction to Power Transformation  
-> Applying `yeo-johnson` and `box-cox` transformations  
-> Comparing distributions before and after transformation  
-> Effect of PowerTransformer on model performance  


# Libraries Used:-
-> pandas  
-> numpy  
-> matplotlib / seaborn  
-> scikit-learn  


# Key Takeaway:-
`PowerTransformer` helps:-
  -> Normalize skewed features  
  -> Stabilize variance  
  -> Improve model convergence and accuracy  


=> Note:-  The notebook includes practical examples comparing feature distributions before and after using `PowerTransformer`.
